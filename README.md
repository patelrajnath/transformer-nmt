# Introduction

This project is created mainly to understand the transformer model of 
Neural Machine Translation. The most modules of the code has been taken from- 
http://nlp.seas.harvard.edu/2018/04/03/attention.html


## Pre-requisites

* pytorch
* numpy 
* torchtext
* spacy

## Quick Start
Train toy model on synthesized data.
```bash
$python3 train_toy.py
```
or

Train a real de-en model using default configuration.
```bash
$python train.py
```
